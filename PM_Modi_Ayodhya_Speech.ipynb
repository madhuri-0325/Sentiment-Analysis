{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d384b9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in c:\\users\\hp\\anaconda3\\lib\\site-packages (5.20.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from plotly) (8.2.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from plotly) (23.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ordcloud (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Error parsing dependencies of pyodbc: Invalid version: '4.0.0-unsupported'\n",
      "WARNING: Error parsing dependencies of pyzmq: Invalid version: 'cpython'\n",
      "WARNING: Ignoring invalid distribution -ordcloud (c:\\users\\hp\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\hp\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 106, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"c:\\users\\hp\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 97, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"c:\\users\\hp\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"c:\\users\\hp\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 484, in run\n",
      "    installed_versions[distribution.canonical_name] = distribution.version\n",
      "  File \"c:\\users\\hp\\anaconda3\\lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py\", line 192, in version\n",
      "    return parse_version(self._dist.version)\n",
      "  File \"c:\\users\\hp\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 56, in parse\n",
      "    return Version(version)\n",
      "  File \"c:\\users\\hp\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 202, in __init__\n",
      "    raise InvalidVersion(f\"Invalid version: {version!r}\")\n",
      "pip._vendor.packaging.version.InvalidVersion: Invalid version: '4.0.0-unsupported'\n"
     ]
    }
   ],
   "source": [
    "#!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "267a91d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud.color_from_image'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-68c66ba83eaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m \u001b[1;31m# it will give meaning root word with dctionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[1;31m#Sentument -some word negtive s\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"punkt\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#need for tokenzation ..abbrebation read adj etc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"stopwords\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#is am are and but a an the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m from .wordcloud import (WordCloud, STOPWORDS, random_color_func,\n\u001b[0;32m      2\u001b[0m                         get_single_color_func)\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcolor_from_image\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageColorGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m __all__ = ['WordCloud', 'STOPWORDS', 'random_color_func',\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud.color_from_image'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import re \n",
    "import nltk #natural lng tool kit\n",
    "from nltk.corpus import stopwords #corpus- complte review\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize #it will split sentence by sentence\n",
    "from nltk.stem import WordNetLemmatizer # it will give meaning root word with dctionary\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer#Sentument -some word negtive s\n",
    "from wordcloud import WordCloud\n",
    "nltk.download(\"punkt\") #need for tokenzation ..abbrebation read adj etc\n",
    "nltk.download(\"stopwords\") #is am are and but a an the\n",
    "nltk.download('vader_lexicon') #categorize postive and negative words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e9328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open and read speech text file \n",
    "file_path = \"PMSPEECH.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    speech_textH = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d4bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_textH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66497de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open and read speech text file \n",
    "file_path = \"PMSPEECH_english.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    speech_textE = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e6c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_textE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229fcc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a29cb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text=re.sub(r'\\u200b','',speech_textE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce983a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d4901e",
   "metadata": {},
   "source": [
    "### Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fd151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text= clean_text.lower()                  # converting to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf87404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string                                    # removing all punctuations from text  \n",
    "for i in cleaned_text:\n",
    "    if i in string.punctuation:\n",
    "        cleaned_text=cleaned_text.replace(i,'')\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a71db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(cleaned_text)                 #converting whole text to words and removig stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "word_filtered = [word for word in words if word not in stop_words]\n",
    "word_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a8c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization           \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words_lemmatized = [lemmatizer.lemmatize(word) for word in word_filtered]\n",
    "words_lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3610c786",
   "metadata": {},
   "source": [
    "### Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33444063",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "sentiment_scores = [sia.polarity_scores(word)['compound'] for word in words_lemmatized]\n",
    "average_sentiment = sum(sentiment_scores) / len(sentiment_scores)\n",
    "average_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25959d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentiment_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046ca4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = [word for i, word in enumerate(word_filtered) if sentiment_scores[i] > 0.1]\n",
    "negative_words = [word for i, word in enumerate(word_filtered) if sentiment_scores[i] < -0.1]\n",
    "neutral_words = [word for i, word in enumerate(word_filtered) if sentiment_scores[i] >=-0.1 and\n",
    "                sentiment_scores[i] <= 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adf48f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The postive words are :\", positive_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfb3afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The negative_words are :\", negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b95fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The neutral_words are :\", neutral_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaf6178",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_postive = nltk.FreqDist(positive_words)\n",
    "word_freq_negative = nltk.FreqDist(negative_words)\n",
    "word_freq_neutral = nltk.FreqDist(neutral_words)\n",
    "print(word_freq_postive)\n",
    "print(word_freq_negative)\n",
    "print(word_freq_neutral)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e905951",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda19612",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.subplot(131)\n",
    "word_freq_postive.plot(20, title=\"Top 20 Positive Sentiment Words\")\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(132)\n",
    "word_freq_negative.plot(20, title=\"Top 20 Negative Sentiment Words\")\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(133)\n",
    "word_freq_neutral.plot(20, title=\"Top 20 Neutral Sentiment Words\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecf255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = pd.DataFrame(word_freq_postive.most_common(10), columns=['Word','Frequency'])\n",
    "df_negative = pd.DataFrame(word_freq_negative.most_common(10), columns=['Word','Frequency'])\n",
    "df_neutral = pd.DataFrame(word_freq_neutral.most_common(10), columns=['Word','Frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d9596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa4995",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714cb916",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neutral.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d726b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_postive = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq_postive)\n",
    "wordcloud_negative = WordCloud(width=800, height=400, background_color='blue').generate_from_frequencies(word_freq_negative)\n",
    "wordcloud_neutral = WordCloud(width=800, height=400, background_color='black').generate_from_frequencies(word_freq_neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab490223",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "\n",
    "plt.imshow(wordcloud_postive, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"Positive Sentiment Words\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0918d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "plt.imshow(wordcloud_negative, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"Negative Sentiment Words\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a131d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "plt.imshow(wordcloud_neutral, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"Neutral Sentiment Words\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
